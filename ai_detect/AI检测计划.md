# ğŸš€ TinyLogBERT - æ— ç›’æ ‡æ—¥å¿—å¼‚å¸¸æ£€æµ‹ç®€å•ç‰ˆé¡¹ç›®è®¾è®¡

## ç›®æ ‡

åœ¨ 2 å¤©å†…å®Œæˆä¸€ä¸ªå¯è¿è¡Œã€å¯æ‰©å±•ã€å¯æ¸…æ™°é‡åŒ–æ— ç›’æ ‡æ—¥å¿—å¼‚å¸¸æ£€æµ‹ç³»ç»ŸåŸå‹ï¼ŒåŸºäº TinyLogBERT å¾®è°ƒã€‚

---

## å†…å®¹

### âœ… æ¨¡å—åŒ–è®¾è®¡

| æ¨¡å— | åŠŸèƒ½ |
|--------|------|
| `log_parser.py` | æ—¥å¿—è½¬æ¢ Token/Text |
| `anomaly_detector.py` | å¾®è°ƒ TinyBERT + è¾“å‡ºå¼‚å¸¸å¾—åˆ† |
| `anomaly_routes.py` | APIæ¥å£ï¼Œæ¥æ”¶æ—¥å¿—ï¼Œè¿”å›å¼‚å¸¸ç»“æœ |
| `evaluate.py` | ROC-AUC/åˆ†æ•°åˆ†å¸ƒç­‰é‡åŒ–æ— ç›’æ ‡æ•ˆæœ |

---

## æ—¥å¿—æ•°æ®é›†

### é€‰æ‹©: [HDFS æ—¥å¿—æ•°æ®é›†](https://github.com/logpai/loghub)
- æ—¥å¿—æ ¼å¼ç®€å•ï¼Œå«æœ‰æ¨¡æ¿ IDï¼Œé€‚åˆæ— ç›’æ ‡å­¦ä¹ 
- é€‰å– 5~10 ä¸‡æ¡æ—¥å¿—è¿›è¡Œé¢„å¤„ç†

```
2023-10-10 08:02:30.123 INFO DFSClient: Successfully read block BP-xxx
```

è½¬æ¢ä¸º:
```
["dfsclient", "successfully", "read", "block"]
```

---

## ç›®å½•ç»“æ„æ‰©å±•

åœ¨ä½ çš„ç›®å½•åŸºç¡€ä¸Šï¼Œå¢åŠ :

```
app/
|â€” models/
|   |â€” tinylogbert_model.py     # åŸºäº BERT-mini çš„ TinyLogBERT + å¼‚å¸¸å¤´
|â€” services/
|   |â€” log_tokenizer.py         # è½¬ token åˆ†è¯å™¨
|   |â€” anomaly_score.py         # æ ¹æ®è¾“å…¥æ—¥å¿—è¿”å›å¼‚å¸¸åˆ†
|   |â€” evaluate.py              # æ•ˆæœé‡åŒ–æ¨¡å—
```

---

## æ ¸å¿ƒä»£ç 

### ã€models/tinylogbert_model.pyã€‘
```python
from transformers import BertModel
import torch.nn as nn

class TinyLogBERT(nn.Module):
    def __init__(self, base_model):
        super().__init__()
        self.encoder = base_model
        self.anomaly_head = nn.Sequential(
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 1)  # è¿”å›å¼‚å¸¸åˆ†
        )

    def forward(self, input_ids, attention_mask):
        x = self.encoder(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:,0,:]
        return self.anomaly_head(x)
```

### ã€services/anomaly_score.pyã€‘
```python
import torch
from transformers import BertTokenizer
from app.models.tinylogbert_model import TinyLogBERT

base_model = BertModel.from_pretrained('prajjwal1/bert-mini')
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = TinyLogBERT(base_model)
model.load_state_dict(torch.load("./checkpoint/model.pt"))
model.eval()

def get_anomaly_score(log_text):
    tokens = tokenizer(log_text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        score = model(**tokens)
    return float(score.item())
```

### ã€services/evaluate.pyã€‘
```python
from sklearn.metrics import roc_auc_score

def evaluate_scores(scores, labels):
    auc = roc_auc_score(labels, scores)
    print("ROC-AUC:", auc)
    return auc
```

---

## å¼€å‘æ—¶é—´è¡¨

| æ—¶é—´ | ä»»åŠ¡ |
|------|------|
| D1-AM | æ•°æ®è½¬åŒ–ï¼ŒåŠ è½½ BERT-miniï¼Œå»ºç«‹ TinyLogBERT + Head |
| D1-PM | è¾“å…¥æ—¥å¿— è½¬åˆ†è¯ï¼ŒåŸ¹è®­ MLM äº”è½®ï¼Œä¿å­˜æ¨¡å‹ |
| D2-AM | è¿è¡Œ scoreï¼Œæ‰©å±• Flask API + CLI |
| D2-PM | é‡åŒ– evaluate.py è¾“å‡º AUC + t-SNE å¯è§†åŒ– |

---

å¦‚éœ€è¦ï¼š
- æŒ‰éœ€é™„ä¸Š notebook æ¨¡å‹è®­ç»ƒè„šæœ¬
- æä¾› FastAPI/åˆ†å¸ƒå¼æ”¯æŒ
- æ”¹é€ å¼‚å¸¸å¤´è¾“å‡º softmax åˆ†çº§åˆ†ç±»

